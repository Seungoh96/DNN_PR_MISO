{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two Way Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import math\n",
    "from utility_func import *\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from time import gmtime, strftime\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Device will determine whether to run the training on GPU or CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Simulation and Hyperparameters\n",
    "Setting up the hyperparameters for the training purpose.\n",
    "\n",
    "$N$: Number of Transmitters. \\\n",
    "$M$: Number of Receivers. \\\n",
    "$L$: Total length of pilot transmission. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define communication parameters \n",
    "N = 64                              # Number of transmit antenna\n",
    "M = 1                               # Number of receive antenna\n",
    "L = 4                              # Number of ping pong rounds\n",
    "SNR_dB = torch.tensor(0)            # Signal to Noise Ratio in dB\n",
    "P_dBm = torch.tensor(0)             # Transmitter and Receiver's power\n",
    "SNR = 10**(SNR_dB/10)               # Signal to Noise Ratio in linear scale\n",
    "P = 10**(P_dBm/10)                  # Transmit power in linear scale\n",
    "N0 = P/SNR                          # Noise power in linear scale\n",
    "\n",
    "# Define hyperparameters\n",
    "batch_size = 1024\n",
    "n_epochs = 20\n",
    "max_epochs = 50\n",
    "\n",
    "# Define parameters for NN \n",
    "input_sizeTx, input_sizeRx = 2*N*L, 2*L\n",
    "output_sizeTx, output_sizeRx = 3*N, M                     # Output size of sensing output of A \n",
    "sim_parameters = (N, M, L, N0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Sensing Data for Pilot Transmission\n",
    "Note that it is crucial to use the same sensing data during pilot stage so that the neural network is able to learn the channel distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Make sensing polarization vectors and beamformer\"\"\"\n",
    "# Polarization vectors used in pilot stage\n",
    "Pol_Tx, Pol_Rx, Pol_Tx_t_blk, Pol_Rx_t_blk = MISO_polarization_pilot_tensor(N, M, L)\n",
    "Pol_Tx_r_blk_T = torch.transpose(Pol_Tx_t_blk, 1, 2)\n",
    "Pol_Rx_r_blk_T = torch.transpose(Pol_Rx_t_blk, 1, 2)\n",
    "\n",
    "# Transmit beamformer used in the pilot stage\n",
    "W_A_t_real = torch.randn((L, 1, N))\n",
    "W_A_t_imag = torch.randn((L, 1, N))\n",
    "W_A_t = torch.complex(W_A_t_real, W_A_t_imag)\n",
    "W_A_t = W_A_t / torch.norm(W_A_t, dim=2, keepdim=True)\n",
    "W_A_t = torch.transpose(W_A_t, 1, 2) * torch.sqrt(P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Generate H_p channel batch data\"\"\"\n",
    "# total number of generated samples\n",
    "num_generated_sample = batch_size * 100 \n",
    "# H_p generation\n",
    "H_p_training_shaped = channel_generation_batch_tensor(num_generated_sample, N, M)\n",
    "y_real_tx_train, y_real_rx_train = generate_twoway_pilots(H_p_training_shaped, Pol_Tx_t_blk, \n",
    "                                                          Pol_Tx_r_blk_T, Pol_Rx_t_blk, Pol_Rx_r_blk_T, \n",
    "                                                          W_A_t, sim_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Generate H_p channel batch data\"\"\"\n",
    "# total number of generated samples\n",
    "num_generated_testing_sample = 1000\n",
    "# H_p generation\n",
    "H_p_testing_batch = channel_generation_batch_tensor(num_generated_testing_sample, N, M)\n",
    "y_real_tx_test, y_real_rx_test = generate_twoway_pilots(H_p_testing_batch, Pol_Tx_t_blk,\n",
    "                                                        Pol_Tx_r_blk_T, Pol_Rx_t_blk, Pol_Rx_r_blk_T,\n",
    "                                                        W_A_t, sim_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two Way Protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TwoWay(H, MLP_tx, MLP_rx, y_real_tx, y_real_rx):\n",
    "    'Calculate final optimal outputs'\n",
    "    # Transmitter side \n",
    "    output_A_t = MLP_tx(y_real_tx)\n",
    "    angle_A_t = torch.sigmoid(output_A_t[:,:N]) * torch.pi\n",
    "    angle_A_t = angle_A_t.unsqueeze(1)\n",
    "    Pol_A_t = torch.hstack((torch.cos(angle_A_t), torch.sin(angle_A_t)))\n",
    "    Pol_A_t_blk = vec2block_diag(Pol_A_t).to(torch.complex64)\n",
    "\n",
    "    W_A_t = output_A_t[:,N:]\n",
    "    W_A_t_norm = torch.norm(W_A_t, dim=1,keepdim=True)\n",
    "    W_A_t = W_A_t/W_A_t_norm\n",
    "    W_A_t = torch.complex(W_A_t[:,:N], W_A_t[:,N:])\n",
    "    W_A_t = W_A_t.unsqueeze(-1)\n",
    "    \n",
    "    # Receiver side\n",
    "    output_B_r = MLP_rx(y_real_rx)\n",
    "    angle_B_r = torch.sigmoid(output_B_r) * torch.pi\n",
    "    Pol_B_r = torch.hstack((torch.cos(angle_B_r), torch.sin(angle_B_r)))\n",
    "    Pol_B_r = Pol_B_r.unsqueeze(-1)\n",
    "    Pol_B_r_blk = vec2block_diag(Pol_B_r)\n",
    "    Pol_B_r_blk_T = torch.transpose(Pol_B_r_blk, 1, 2).to(torch.complex64)\n",
    "\n",
    "    Heff_final = Pol_B_r_blk_T @ H @ Pol_A_t_blk\n",
    "    y_final = Heff_final @ W_A_t\n",
    "    \n",
    "    return y_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Model Class \n",
    "It is easy to define the Fully Connected Neural Network in this way becuase dimension can arbitrarly change. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPBlock(nn.Module):\n",
    "    def __init__(self, num_layers, dims):\n",
    "        super(MLPBlock, self).__init__()\n",
    "\n",
    "        layers = []\n",
    "        for i in range(num_layers - 2):\n",
    "            layers.append(nn.Linear(dims[i], dims[i + 1]))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.BatchNorm1d(dims[i + 1]))\n",
    "\n",
    "        layers.append(nn.Linear(dims[-2], dims[-1]))\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return self.mlp(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beamforming Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BeamformingModel(nn.Module):\n",
    "    def __init__(self, MLP_tx_dim, MLP_rx_dim):\n",
    "        super(BeamformingModel, self).__init__()\n",
    "        self.MLP_tx = MLPBlock(len(MLP_tx_dim), MLP_tx_dim)\n",
    "        self.MLP_rx = MLPBlock(len(MLP_rx_dim), MLP_rx_dim)\n",
    "\n",
    "    def forward(self, H, y_tx, y_rx):\n",
    "        bf_loss = TwoWay(H, self.MLP_tx, self.MLP_rx, y_tx, y_rx)\n",
    "        \n",
    "        return bf_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beamforming Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beamforming_loss(bf):\n",
    "    bf_gain = torch.mean(torch.abs(bf)**2)\n",
    "    return -bf_gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/seungcheoloh/Desktop/Primary/Research/DNN Applied P_MIMO/Two_Way_Method/trained_TwoWay_model/02-09_15_06_02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]/Users/seungcheoloh/opt/anaconda3/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:587: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "  2%|▏         | 1/50 [00:44<36:32, 44.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0   loss_train:4.34208   loss_test:4.39170   best_test:-inf   no_increase: 0 lr: [0.0009833337214848017]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [01:30<36:29, 45.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1   loss_train:5.19307   loss_test:5.15294   best_test:4.39170   no_increase: 0 lr: [0.0009677193833158022]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [02:15<35:28, 45.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2   loss_train:5.46991   loss_test:5.44418   best_test:5.15294   no_increase: 0 lr: [0.0009523529849368548]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [02:59<34:16, 44.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3   loss_train:5.59695   loss_test:5.57399   best_test:5.44418   no_increase: 0 lr: [0.0009372305893165697]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [03:44<33:28, 44.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4   loss_train:5.68635   loss_test:5.66323   best_test:5.57399   no_increase: 0 lr: [0.0009223483219396084]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/50 [04:27<32:21, 44.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5   loss_train:5.74202   loss_test:5.72878   best_test:5.66323   no_increase: 0 lr: [0.0009077023698139884]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [05:10<31:18, 43.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6   loss_train:5.77607   loss_test:5.76304   best_test:5.72878   no_increase: 0 lr: [0.0008932889804941583]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8/50 [05:53<30:29, 43.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7   loss_train:5.79881   loss_test:5.77935   best_test:5.76304   no_increase: 0 lr: [0.0008791044611195806]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9/50 [06:36<29:35, 43.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8   loss_train:5.80112   loss_test:5.79044   best_test:5.77935   no_increase: 0 lr: [0.0008651451774685831]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [07:19<28:50, 43.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9   loss_train:5.82346   loss_test:5.79931   best_test:5.79044   no_increase: 0 lr: [0.0008514075530272329]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [08:01<27:56, 42.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10   loss_train:5.81796   loss_test:5.81000   best_test:5.79931   no_increase: 0 lr: [0.000837888068072996]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12/50 [08:44<27:08, 42.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11   loss_train:5.82843   loss_test:5.82304   best_test:5.81000   no_increase: 0 lr: [0.0008245832587729483]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13/50 [09:27<26:33, 43.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12   loss_train:5.83960   loss_test:5.83935   best_test:5.82304   no_increase: 0 lr: [0.0008114897162963057]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 14/50 [10:10<25:45, 42.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13   loss_train:5.86721   loss_test:5.85775   best_test:5.83935   no_increase: 0 lr: [0.000798604085941045]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [10:52<24:55, 42.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14   loss_train:5.88497   loss_test:5.87540   best_test:5.85775   no_increase: 0 lr: [0.0007859230662743959]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16/50 [11:37<24:37, 43.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15   loss_train:5.90120   loss_test:5.89458   best_test:5.87540   no_increase: 0 lr: [0.0007734434082869778]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 17/50 [12:21<23:53, 43.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16   loss_train:5.91574   loss_test:5.91173   best_test:5.89458   no_increase: 0 lr: [0.0007611619145603713]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 18/50 [13:05<23:15, 43.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17   loss_train:5.94177   loss_test:5.92665   best_test:5.91173   no_increase: 0 lr: [0.0007490754384479052]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19/50 [13:50<22:43, 44.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18   loss_train:5.95028   loss_test:5.93907   best_test:5.92665   no_increase: 0 lr: [0.0007371808832684528]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [14:33<21:55, 43.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19   loss_train:5.95507   loss_test:5.95115   best_test:5.93907   no_increase: 0 lr: [0.0007254752015130315]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [15:16<21:02, 43.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20   loss_train:5.96257   loss_test:5.96172   best_test:5.95115   no_increase: 0 lr: [0.0007139553940639969]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22/50 [15:59<20:11, 43.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21   loss_train:5.97881   loss_test:5.96887   best_test:5.96172   no_increase: 0 lr: [0.0007026185094266397]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 23/50 [16:41<19:23, 43.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22   loss_train:5.97633   loss_test:5.97416   best_test:5.96887   no_increase: 0 lr: [0.0006914616429729803]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 24/50 [17:24<18:39, 43.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23   loss_train:5.99885   loss_test:5.97946   best_test:5.97416   no_increase: 0 lr: [0.0006804819361975742]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [18:07<17:56, 43.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24   loss_train:5.99096   loss_test:5.98348   best_test:5.97946   no_increase: 0 lr: [0.0006696765759851322]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 26/50 [18:50<17:13, 43.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25   loss_train:5.99313   loss_test:5.98626   best_test:5.98348   no_increase: 0 lr: [0.0006590427938897716]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 27/50 [19:33<16:24, 42.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26   loss_train:5.98120   loss_test:5.98911   best_test:5.98626   no_increase: 0 lr: [0.0006485778654257108]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 28/50 [20:18<15:55, 43.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27   loss_train:5.99637   loss_test:5.99164   best_test:5.98911   no_increase: 0 lr: [0.0006382791093692286]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 29/50 [21:01<15:11, 43.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28   loss_train:6.00677   loss_test:5.99281   best_test:5.99164   no_increase: 0 lr: [0.0006281438870717055]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [21:44<14:24, 43.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29   loss_train:5.99931   loss_test:5.99441   best_test:5.99281   no_increase: 0 lr: [0.000618169601783576]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [22:26<13:37, 43.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30   loss_train:6.00104   loss_test:5.99532   best_test:5.99441   no_increase: 0 lr: [0.0006083536979890128]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [23:17<13:36, 45.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31   loss_train:6.00101   loss_test:5.99570   best_test:5.99532   no_increase: 0 lr: [0.0005986936607511782]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [24:01<12:46, 45.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32   loss_train:6.00121   loss_test:5.99722   best_test:5.99570   no_increase: 0 lr: [0.0005891870150678697]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 34/50 [24:45<11:52, 44.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33   loss_train:6.01111   loss_test:5.99827   best_test:5.99722   no_increase: 0 lr: [0.0005798313252374002]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [25:27<10:56, 43.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34   loss_train:6.00351   loss_test:5.99778   best_test:5.99827   no_increase: 0 lr: [0.000570624194234545]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 36/50 [26:11<10:15, 43.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35   loss_train:6.00626   loss_test:5.99778   best_test:5.99827   no_increase: 1 lr: [0.0005615632630963988]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 37/50 [26:53<09:24, 43.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36   loss_train:6.00718   loss_test:5.99844   best_test:5.99827   no_increase: 2 lr: [0.0005526462103179852]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 38/50 [27:36<08:39, 43.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 37   loss_train:6.01210   loss_test:5.99941   best_test:5.99844   no_increase: 0 lr: [0.0005438707512574627]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 39/50 [28:19<07:54, 43.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38   loss_train:6.00401   loss_test:5.99942   best_test:5.99941   no_increase: 0 lr: [0.0005352346375507765]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [29:01<07:08, 42.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39   loss_train:6.00499   loss_test:6.00012   best_test:5.99942   no_increase: 0 lr: [0.0005267356565356023]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [29:44<06:25, 42.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40   loss_train:6.01277   loss_test:5.99958   best_test:6.00012   no_increase: 0 lr: [0.0005183716306844416]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 42/50 [30:28<05:46, 43.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41   loss_train:6.00420   loss_test:5.99964   best_test:6.00012   no_increase: 1 lr: [0.0005101404170467145]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 43/50 [31:12<05:03, 43.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42   loss_train:6.01948   loss_test:6.00059   best_test:6.00012   no_increase: 2 lr: [0.0005020399066997145]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 44/50 [31:55<04:19, 43.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 43   loss_train:6.01194   loss_test:6.00041   best_test:6.00059   no_increase: 0 lr: [0.0004940680242082795]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [32:38<03:36, 43.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44   loss_train:6.01114   loss_test:6.00099   best_test:6.00059   no_increase: 1 lr: [0.00048622272709304524]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 46/50 [33:22<02:53, 43.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45   loss_train:5.99787   loss_test:6.00069   best_test:6.00099   no_increase: 0 lr: [0.00047850200530713907]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 47/50 [34:05<02:10, 43.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 46   loss_train:6.01196   loss_test:6.00091   best_test:6.00099   no_increase: 1 lr: [0.00047090388072118625]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 48/50 [34:49<01:26, 43.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47   loss_train:6.00873   loss_test:6.00104   best_test:6.00099   no_increase: 2 lr: [0.00046342640661649256]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 49/50 [35:32<00:43, 43.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48   loss_train:6.01835   loss_test:6.00099   best_test:6.00104   no_increase: 0 lr: [0.00045606766718627356]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [36:14<00:00, 43.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 49   loss_train:6.00687   loss_test:6.00081   best_test:6.00104   no_increase: 1 lr: [0.00044882577704480624]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAkNElEQVR4nO3deXRed33n8ff32bRL1mZbsi3LW+LYgTjBCVmBkIQSE2JSSoG2aXo6p6EcaAtTSmk5pczMYSZDoZlOS2kDhKaUKUshhSYpZGFNyOYEx7vxEju2JcuSbe3Ls33nj+c6UYxkWeuVdD+vc55z9+d+f1700d1+19wdERGJrljYBYiISLgUBCIiEacgEBGJOAWBiEjEKQhERCIuEXYBE1FXV+fNzc1hlyEiMqc899xzHe5ef/b8ORkEzc3NbNmyJewyRETmFDM7PNJ8nRoSEYk4BYGISMQpCEREIk5BICIScQoCEZGIUxCIiEScgkBEJOIiFQQ/2NPG3/9of9hliIjMKpEKgp/8ooN/+NGBsMsQEZlVIhUElcUJeoay5PN6GY+IyBnRCoKSJO7Qm86GXYqIyKwRrSAoTgLQPZAJuRIRkdkjWkFQUuhjr3tARwQiImdEKghWH72f/5X4At2DOiIQETkjUkGwoHc/t8SfomdQRwQiImdEKggSZTVU2AA9ff1hlyIiMmtEKghS5TUADPWeCrkSEZHZI1JBUFRRC0C6R0EgInJGpIIgXlYIgly/gkBE5IxIBQEl1QB4/+mQCxERmT0iFgQLALDBzlDLEBGZTSIWBIUjgvhQZ7h1iIjMItEKguIqAJLpznDrEBGZRaIVBLE4/bFyUpnusCsREZk1piQIzOwjZuZmVjfK8kNmtt3MtprZlmHza8zsETPbFwyrp6KecxlMVFKcVRCIiJwx6SAws2XATcBLY6x6vbtvcPeNw+Z9DHjM3dcAjwXT0yqdrKQs14O73kkgIgJTc0RwN/BRYCI/WTcD9wXj9wHvmIJ6zimbWkCV9dKXzk33rkRE5oRJBYGZ3Qocc/cXxljVgYfN7Dkzu3PY/EXu3goQDBeeY193mtkWM9vS3t4+4ZrzxVVU0UePeiAVEQEgMdYKZvYosHiERR8H/hx4y3ns5xp3bzGzhcAjZrbH3X8ynkLd/R7gHoCNGzdO+LyOF1dTZX2cHMjSUDXRbxERmT/GDAJ3v3Gk+Wb2GmAF8IKZASwFnjezK9z9+Fnf0RIMT5jZ/cAVwE+ANjNrcPdWM2sATkyqNechVlrNAnp5cSA93bsSEZkTJnxqyN23u/tCd29292bgKHDZ2SFgZmVmVnFmnMIRxI5g8XeBO4LxO4DvTLSe8xUvqyFhefp6Oqd7VyIic8K0PEdgZo1m9lAwuQh43MxeAJ4BHnT37wXL7gJuMrN9FO48ums66hkuGXRFPdhzcrp3JSIyJ4x5auh8BUcFZ8ZbgE3B+EHgklG2OQncMFU1nI8zXVFnFAQiIkDUniwGSioLz7xl9XIaEREggkGQLC8cEfiguqIWEYEIBsGZrqgZ6AyzChGRWSOCQVDoziimIwIRESCKQZAsYYgUiaGusCsREZkVohcEQH+8glRGQSAiAhENgoF4BUXqilpEBIhoEKSTVZTmesIuQ0RkVohkEGRSVZS73kkgIgIRDYJcURVV9DKYyYddiohI6CIZBF5cTRV9dOudBCIi0QwCK62mzIbo6e0NuxQRkdBFMghiZYUeSPu61PGciEgkgyBZVni6eLBbQSAiEskgKKoo9ECa7lUQiIhEMghe7oq6T11Ri4hEMghKqwpBkFMQiIhEMwiKKgoXi9UVtYhIRIOAoiryGDbYGXYlIiKhi2YQxGL0UE5iqDPsSkREQjclQWBmHzEzN7O6EZZdaGZbh326zexDwbJPmtmxYcs2TUU956MvXkFSXVGLiJCY7BeY2TLgJuClkZa7+15gQ7BuHDgG3D9slbvd/TOTrWO8BuIVFGXUFbWIyFQcEdwNfBQ4n648bwAOuPvhKdjvpAwlKinNKQhERCYVBGZ2K3DM3V84z03eA/zrWfM+aGbbzOxeM6s+x77uNLMtZralvb19oiW/LJOqoiyvdxKIiIwZBGb2qJntGOGzGfg48Inz2ZGZpYBbgW8Om/15YBWFU0etwGdH297d73H3je6+sb6+/nx2eU7ZVBUV3jfp7xERmevGvEbg7jeONN/MXgOsAF4wM4ClwPNmdoW7Hx9hk5uB5929bdh3vzxuZl8AHhhf+ROXL15AJb0MpjMUp5IztVsRkVlnwqeG3H27uy9092Z3bwaOApeNEgIA7+Ws00Jm1jBs8jZgx0TrGS8rrSFuTk+Xni4WkWiblucIzKzRzB4aNl1K4c6ib5+16qfNbLuZbQOuBz48HfWMJFZauBzR19kxU7sUEZmVJn376BnBUcGZ8RZg07DpfqB2hG1un6r9j1cieCfBYI96IBWRaIvmk8VAqqKQS2kFgYhEXGSDoKSyEAQZvZNARCIuskFQVlW4BVVdUYtI1EU4CArdIrm6ohaRiItsEBSXlNDvRdjg6bBLEREJVWSDwMzotnLieieBiERcZIMAoC9WQUI9kIpIxEU6CPpjFRTpnQQiEnGRDoLBZCUlWR0RiEi0RToI0kl1RS0iEukgyKYqKffesMsQEQlVpIMgX1xNMWnIDIRdiohIaCIdBBQvACDdq6eLRSS6Ih0EsaAH0v7Oyb/6UkRkrop0ECSCdxL09+iIQESiK9JBkAy6oh7q1stpRCS6Ih0ExRWFjufUFbWIRFmkg6Ak6IE026eO50QkuiIdBOWVC8h6jHy/rhGISHRFOggqS1J0UYbpnQQiEmGRDoLSVJwuyokPdYZdiohIaCYVBGb2STM7ZmZbg8+mUdZ7q5ntNbP9ZvaxYfNrzOwRM9sXDKsnU894mRm9Vk4irR5IRSS6puKI4G533xB8Hjp7oZnFgc8BNwPrgPea2bpg8ceAx9x9DfBYMD2j+uMVpNQVtYhE2EycGroC2O/uB909DXwN2Bws2wzcF4zfB7xjBup5lYF4JcXqilpEImwqguCDZrbNzO4d5dTOEuDIsOmjwTyARe7eChAMF462EzO708y2mNmW9vap6xJiKFlFaU5dUYtIdI0ZBGb2qJntGOGzGfg8sArYALQCnx3pK0aY5+Mt1N3vcfeN7r6xvr5+vJuPKpuqotT7IJ+bsu8UEZlLEmOt4O43ns8XmdkXgAdGWHQUWDZseinQEoy3mVmDu7eaWQNw4nz2NZVyRVXEcBjsgtKamd69iEjoJnvXUMOwyduAHSOs9iywxsxWmFkKeA/w3WDZd4E7gvE7gO9Mpp4JKQnOZg3o6WIRiabJXiP4tJltN7NtwPXAhwHMrNHMHgJw9yzwQeD7wG7gG+6+M9j+LuAmM9sH3BRMzygLjgKy/QoCEYmmMU8NnYu73z7K/BZg07Dph4BfurXU3U8CN0ymhsmKly4AYKCrg4pl515XRGQ+ivSTxQDJ8kJX1IM96opaRKIp8kGQCrqiTuvlNCISUZEPgtLK4BpBn4JARKIp8kFQUVZKrxeTVxCISERFPggqS5J0Ug6DnWGXIiISCgVBcYIuLyM2qNtHRSSaIh8EZakEXZQRH1IPpCISTZEPgljM6ItVkMqoB1IRiabIBwEEXVHrnQQiElEKAmAwUUVJrgd83J2iiojMeQoCIJuqJEkGMgNhlyIiMuMUBEC2aEFhpP9kqHWIiIRBQQD0lwW9zZ3cH24hIiIhUBAAvVUXFkbaRnqdgojI/KYgABKV9bT5AvLHFQQiEj0KAqCiOMnu/HL8+M6xVxYRmWcUBMCCkiR7vIlYx17IZcIuR0RkRikIgAsWVbA7vwzLp6FjX9jliIjMKAUBsGZROb+w5sJEm04PiUi0KAiA4mScWN0asiSgbXvY5YiIzKhJBYGZfdLMjpnZ1uCzaYR1lpnZD81st5ntNLM/Gs/2M+XCJTUcZKmOCEQkchJT8B13u/tnzrE8C/yxuz9vZhXAc2b2iLvvOs/tZ8T6xiq2b1/GquM7iIddjIjIDJr2U0Pu3uruzwfjPcBuYMl073e81jVUsjvfRLz3OPSpqwkRiY6pCIIPmtk2M7vXzKrPtaKZNQOXAk+Pd3szu9PMtpjZlvb29iko+9XWNVayx5sKE3rCWEQiZMwgMLNHzWzHCJ/NwOeBVcAGoBX47Dm+pxz4FvAhdz/zFpjz3t7d73H3je6+sb6+/vxaNw5VJUm6qi4oTCgIRCRCxrxG4O43ns8XmdkXgAdGWZakEAJfdfdvD/vutvPZfqYsaVzOqYMLqNEFYxGJkMneNdQwbPI24Jd+lTYzA74E7Hb3vx7v9jNpXWMlO3PLyKnPIRGJkMleI/i0mW03s23A9cCHAcys0cweCta5BrgdePMIt4mOuH1Y1jdWsivfhJ3YDblsmKWIiMyYSd0+6u63jzK/BdgUjD8O2Hi2D8v6xioeyDcRy6cL7yZYuDbskkREpp2eLB5mUWURrcWrChO6YCwiEaEgGMbMKGlcS5a4gkBEIkNBcJYLltSx35foJTUiEhkKgrOsb6xid34ZuVYFgYhEg4LgLOsaKtmTbyLZ1wr9p8IuR0Rk2ikIzrKirowDsebChB4sE5EIUBCcJR4zfOH6woSCQEQiQEEwgsalzZzyCvy4XlIjIvOfgmAE65ZUsSvfRLpFQSAi85+CYATrgy6pEx17IJ8LuxwRkWmlIBjBBYsq+AXLieeH4OSBsMsREZlWCoIRFCfj9C0I+hnSE8YiMs8pCEZRtmQdWWK6c0hE5j0FwSguWFrPwXwDQ8e2hV2KiMi0UhCMYn1jFbt9Oa4+h0RknlMQjGJdY6GrieL+FhjoDLscEZFpoyAYRVVJkvay1YUJXScQkXlMQXAO+cbLCu8m2PNg2KWIiEwbBcE5NC9r4nu5y/GtX4XMQNjliIhMCwXBOaxrqOSruRuwwU7Y+e9hlyMiMi0UBOdwadMCnmU9J4ubYMu9YZcjIjItJhUEZvZJMztmZluDz6ZR1jtkZtuDdbYMm19jZo+Y2b5gWD2ZeqZabXkRv7K+gXsHr4ejz4B6IxWReWgqjgjudvcNweehc6x3fbDOxmHzPgY85u5rgMeC6Vnlt65czr8MXkMuloItXw67HBGRKRf2qaHNwH3B+H3AO8IrZWRXrqxh4cLF/Dh5HWz7Bgz1hl2SiMiUmoog+KCZbTOze89xaseBh83sOTO7c9j8Re7eChAMF462EzO708y2mNmW9vb2KSj7/JgZt1+1nL/rvg7SPbDj32Zs3yIiM2HMIDCzR81sxwifzcDngVXABqAV+OwoX3ONu18G3Ax8wMzeMN5C3f0ed9/o7hvr6+vHu/mk3HbpEvYk19JStAqe/RK4z+j+RUSm05hB4O43uvvFI3y+4+5t7p5z9zzwBeCKUb6jJRieAO4ftl6bmTUABMMTU9GoqVZRnOS2S5dyT/8b4fg2aHk+7JJERKbMZO8aahg2eRvwSz20mVmZmVWcGQfeMmy97wJ3BON3AN+ZTD3T6farlvNvmavJxEt0K6mIzCuTvUbw6eC20G3A9cCHAcys0czO3EG0CHjczF4AngEedPfvBcvuAm4ys33ATcH0rLR2cSXrmpfyn3Ydvv1b6ohOROaNxGQ2dvfbR5nfAmwKxg8Cl4yy3knghsnUMJN+66rl/OPX3sStRQ/Dtq/D698XdkkiIpMW9u2jc8pb1y+mrewCDhatLZwe0kVjEZkHFATjkErEeM/lTXy+9w3QvgdeejLskkREJk1BME7vfX0TD+avYiBeCT/5Kx0ViMicpyAYpyULSrj2oiY+l38nHPiB3lUgInOegmACbr9qOf8wcD1dFavh+3+mdxWIyJymIJiAa1bVsWpRNZ9I3wGdL8ETfxN2SSIiE6YgmIBYzPjE29fxna5V7Ku7CR6/G04fDrssEZEJURBM0DWr67j54sX8Xttm8hg8/PGwSxIRmRAFwSR8/G0XcZw6Hqj6Ddj9H3Dgh2GXJCIybgqCSVhaXcr737iaPzl2HYPlTfCffwq5TNhliYiMi4Jgkt73xpXUV1fxP/O/DR174el/DLskEZFxURBMUnEyzl/cso5/PnURR2qvhR/dBT3Hwy5LROS8KQimwFvWLeK6NfX8/sl34bkh+N6f6YljEZkzFARTwMz4y7evZ296Id+v/W3Y+W2dIhKROUNBMEVWLyznd69dwftfehNdTW+B7/85vPiTsMsSERmTgmAK/cGbV1NXUcLtp3+XXM0q+MYdetBMRGY9BcEUqihO8jfv2cCe0/CB/EfwfBa+/puQ7g+7NBGRUSkIptjVq+r4+9+4jEfbKrir9CP48R3wH3+oi8ciMmspCKbBjesW8dfv3sA9x1fzb1W/A9u/CU/+XdhliYiMaFLvLJbR3XpJIwPpLH/yLWdl7QEue+QT2KL1sOrNYZcmIvIqkzoiMLNPmtkxM9safDaNsM6Fw5ZvNbNuM/vQ+W4/l7378ib+4pb13H7ydzieWo5//XZ49ouQz4ddmojIy6biiOBud//MaAvdfS+wAcDM4sAx4P7z3X6u+y/XrqB3MMttj/5XvlJ3H2se/GPY8W249W+hdlXY5YmIzPg1ghuAA+4eqXsq//CG1bzjjVdwU8eH+UzxH5Bt3Qafv7rwQptcNuzyRCTipiIIPmhm28zsXjOrHmPd9wD/OpHtzexOM9tiZlva29snXfRMMjM+dvNavvw7V/Btv55reu5id/kV8Mgn4Es3wvEdYZcoIhFmPsZtjWb2KLB4hEUfB54COgAH/gfQ4O6/O8r3pIAWYL27twXzFp3v9sNt3LjRt2zZMtZqs1LvUJZPf28P//zkIW6v/Dl/EfsyqaHTsOz1cOEmWPs2nTISkWlhZs+5+8Zfmj9WEIxjB83AA+5+8SjLNwMfcPe3TGT74eZyEJzx7KFT/Om3tnGq/Tj/e+mTXM8zpDp2FRbWXQhrN8GFb4PGSyGum7tEZPJGC4JJ/YQxswZ3bw0mbwPOdY7jvZx1Wmic288rlzfX8NAfXsff/mAfH/hxJTl/C+9amed9i/ey8tSPsSf+b+FdyIkSaNwAS14HSy4rDBcsB7OwmyAi88SkjgjM7CsU7ghy4BDwPndvNbNG4IvuvilYrxQ4Aqx0966xth9rv/PhiGC4tu5BvvrUYb769Euc7EuzZmE5v7exms0Veyg6/jwcew6Ob4PsYGGD0lpY/BqovwgWrn1lWFwVbkNEZFab9lNDM2m+BcEZg5kcD25r5cs/e5Edx7qpKE7QVFNKaSpOeRJW+0tckP0FK9N7WJk/xIK+F7HMsH6MKpfAovWF00mNl0LDBqhsCK09IjK7KAjmEHfnucOn+eaWo3T0DtGfztGfyTGQztI3lKNnMEP3YJa60gTvuyTJO5t6qOk7CCf2wPHt0L4bPHhorXxxIRSWXAbLrymcWkoWh9tAEQmFgmAecXce39/BfT87zGN72oiZ8SvrF3HHVc1c3lzDyc5Oug89T/bI8yTbtlJ1eic1A4cwnHy8CFu6EWu+FpqvhaWXQ7Ik7CaJyAxQEMxTR07185WnDvP1Z4/QNZAhZpA/6680ZlAT62eD7+b1sd1cFd/DOjtEjDy5WJLBpddR8pq3E1u7CSpGulNYROYDBcE8N5DO8R8vtHDoZB+LKotZVFnM4qpiFlUWUV9eBMD+9l62H+1iZ0s3B460UHb8WS73bdwYe47lsRMAtJSvp2/Fr1DzundQu/y1ujtJZB5REMgvyeWd/Sd6eeHIaVr3/ZzqI4+woe8JXhs7CMCx5HISl/w6i67+TahZEXK1IjJZCgI5LwPpHPv27+XUc/dTeeC7XMYeAAYXXkrxZe+G9bfp9JHIHKUgkHHrHszw9UefpOuZr3Ezj7M+dhi3GLb8mkIgXHQrlNeHXaaInCcFgUzYyd4hPv+jAzz+1M94mz3Br5dsYVH6pUIoNF/7SiiU1YVdqoicg4JAJq21a4DP/XA/39l6jMahF3ln0bPclnqG+vSRQiiseCO89t1w0duhqDzsckXkLAoCmTJD2RyP7+vgwW2tPLzrOEvTL/JrRU9zW/IpajOteLIUu+jthVBY+SaIxcMuWURQEMg0Gczk+Om+Dh7Y1sIPdrdxYXon70o+wS2JpynL95IvW0Tste+Cde8oPNUcm+l3IYnIGQoCmXbpbJ6nXzzJI7va+PHOI1zU+xS/Gv8p18dfIEmWdFkDifW3Elu3GZqu1JGCyAxTEMiMcnd2tnTzyK42nt51kIa2H3Fz/BneGN9GERkGimrxC2+hdP0mWHEdpMrCLllk3lMQSKhO9g7x+P4Ont79Eux/mKvTT/Dm2FZKbYh8LEWs+WpYfROsvhHqL9QTzSLTQEEgs4a7s7eth+9tPcTOp77PFdnn2VSykyWZw4UVqpZB83Ww/CpougpqVysYRKaAgkBmpa6BDPf97BBfevxFygZaed+Sg2wu382C9i3Qf7KwUmld4ZpCUxAMDa+FeDLcwkXmIAWBzGo9gxn++cnDfOGnB+nsz9BQWcR1Nae5tmg/F2d30tj1AsW9LxVWTpQU3q+w7PXB5woorQm3ASJzgIJA5oTeoSzf3HKEbUe72HeihwMn+hjI5ABYyGmuSe3jqtQBLmUvK7MHiFNY1l3WzNDCSyhquozy5o3EGi+BooowmyIy6ygIZE7K552WrgH2nejlwIlejnUO0NGbpr1nkJ6eHhb37uTC9C4ujR3g4tiLNNipwnYYbcllnK5cS9XStTQ0X0SsdiVUr4DyhbrmIJGkIJB5K53N09Y9yKGTfRxveYnskecp6dhOfe9umjMHaeAkMXvl37knS7HqZqhsLPSkWr64MKxoCIaLoXyRrkPIvDNaECSm4Iv/APggkAUedPePjrDOW4G/AeLAF939rmB+DfB1oBk4BPy6u5+ebE0SLalEjGU1pSyrKYU19cDrXl7WM5jhe7uP8fz2bbQc3EVdpoUV+XZe29NJbdcRKrNbqcqdIk7+Vd/pGJTVYS+HxOLCkURpLZTUFIalNYVPSTWkKiA+9n+n412D7GzpYlV9Oc11enZCZodJHRGY2fXAx4G3ufuQmS109xNnrRMHfgHcBBwFngXe6+67zOzTwCl3v8vMPgZUu/ufjrVfHRHIRGRyeZ598RQP72rjZwc6AChNJShPwcJYHw3x01TnTnH86IuUpTtYXdrLhgWDNMY7ife2QV87eG7U7/dECV5UgaXKseIKPFVOj5fQnknRMpDkUE+M1sEkfZTQRzFlFVWsWbqYi1cs4aLlDRSVVhQuhMeTwScFsWThCWydypIpMF1HBO8H7nL3IYCzQyBwBbDf3Q8GhXwN2AzsCoZvCta7D/gRMGYQiExEMh7j6tV1XL363N1lD2ZyPLitlS88eYhtR7qoKErwaxuXsmFpFS1tbbSfaKWr4zgDXe0UZzpZYH2UMUB5doDywUHKbYAKG6SCk5QyQBmDrI8NcKUNkExmhu0I2B98zskKoZAohkQRJIrxRIqspchYEmIJYvEkFk9g8STxRBKLJbBYDCyGW2H48ieexOJFkCjCEkXBdxa9EjzxRDBMFQLJDNzB85DPFYaeK8wbteRYIcBiiVfGLZiOF2p+ZTx57j6oYolg27O+7+Va8q+u7VV1DAtQiwf7iwf7TLy6fTCsTf7qdljslRosXlju+Zf/XI539/PCkU6WVZeydnElsVgs2Le9MnxVPXbucHcP9jF8GNQVT0159yyTDYILgOvM7FMU/ll/xN2fPWudJcCRYdNHgdcH44vcvRXA3VvNbOEk6xGZtOJknHe+bim/etkSfn6kk3964hBfefIwX847ZrBkQSkr6l7DylVlrKgrY1FlMUPZPP3pHAOZHKfTWQYyOXJ5WNdYyeuWV1NdVYyZQXYIhnohXfgM9XWz+3ALe15q5eCxNnr6+kiSJUmW+tI4SyriNFQkKIll6O/vp7+/n6H+fjJDAyQ9TYoscYZIMEDCsiTIEydHkhzgxF7+5DGcOHmSliVFlhQZishQZNmw/8jnvMXBZyb0/trXKL/45in9zjGDwMweZeQ2fjzYvhq4Ergc+IaZrfRXn28aKfbGfT7KzO4E7gRoamoa7+Yi42ZmXNZUzWVN1fzFLes41ZdmeW0pxclJ/DZ25rfvsloAioANK2FDsPhk7xA7W7rZfqyLbS1dfPVYF0daBoDCtZDlNaUsX1rGirpSltcWQmggl2cwm2Mok2cwk2Mom2comx9x9xD8EosHQyCfI+YZ2k73sL/1NEc6urF8loRlqUw6lUVx2noz5DHyxMgTo6okRU1FCUPZHAPpHH1DWfrThdNmBoW1LE+csz+FkEqQoyIFdSUxqkuMbDbH8e5BBjOvnHpLxeNUlybAc1g+h3sOy2chnyOXy5J1I+cxcsRIJeLUVpZSU1ZM50CG1q5Xf1dpMkY6kyFOjtoSY/3iMtYuLGF1XTFFMRjKOSf70pzqz3CyN83JvjQ9g9lXHwEF45lshtP9ORxIJRMsrS5lWW05S6tLOdU3xKGOXg539NE3lMVwqksTlBUlSL/8d5Mjk33lz6qyNEl9eRH1FcGnvIjSVIK2niFauwZp6RqkpWuInsHCNlf11fGGif8LHNGYQeDuN462zMzeD3w7+MH/jJnlgTqgfdhqR4Flw6aXAi3BeJuZNQRHAw3ASKeWztRxD3APFK4RjFW3yFQ68590utWWF/GGC+p5wwWvvAK0sz9NfzrH4spiYrHpv1YwmMmx/0Qvu1q62dXaTfdAhitry2iuK2VFXRnNdWVUFv/yHVX5vNOXztI3lCOTy5PLO9l8nmzeyeacTC5P50CG9p4h2nuG6OgtDA/1DFGUiLFydRkr68tZVV/Oyvqyc7Y3l3daOgd4saPv5c+ejj6OnO5nUUUxa1aV87qF5axaWM6ahRXUlado7x3ix3vb+eHeE3zzFx30HMiSjBtVJUk6etOv+v5FlUU0VJWQiseIx4xE3ArDmFGUjHPpsgVcubKWixoqiQ+rcQnwGgrdqOw/0cvj+zt4Yv9J+oayVJYkqChOUlmcpLIkQWVxkr6hLD8/3sPu1m5e3Nc34tm25tpSNqxZwKVN1VzatIC1iysn89c7osleLP59oNHdP2FmFwCPAU3DjwjMLEHhYvENwDEKF4t/w913mtlfASeHXSyuGemuo7PpYrGITEYml+e5w6f54d4TdPZlWF5XyoraQsgtry2lNDXpGyrHbSCdY29bIRQ6eoZYv6SSDcuqqSlLTdk+puU5AjNLAfdSOLJNU7hG8AMza6Rwm+imYL1NwP+hcPvove7+qWB+LfANoAl4CXiXu58aa78KAhGR8dMDZSIiETdaEOi9gSIiEacgEBGJOAWBiEjEKQhERCJOQSAiEnEKAhGRiFMQiIhE3Jx8jsDM2oHDE9y8DuiYwnLmCrU7eqLadrV7dMvdvf7smXMyCCbDzLaM9EDFfKd2R09U2652j59ODYmIRJyCQEQk4qIYBPeEXUBI1O7oiWrb1e5xitw1AhERebUoHhGIiMgwCgIRkYiLVBCY2VvNbK+Z7Q/eiDYvmdm9ZnbCzHYMm1djZo+Y2b5gWB1mjdPBzJaZ2Q/NbLeZ7TSzPwrmz+u2m1mxmT1jZi8E7f5vwfx53e4zzCxuZj83sweC6XnfbjM7ZGbbzWyrmW0J5k243ZEJAjOLA58DbgbWAe81s3XhVjVt/gl461nzPgY85u5rKLxSdD4GYRb4Y3e/CLgS+EDwdzzf2z4EvNndL6HwtsC3mtmVzP92n/FHwO5h01Fp9/XuvmHYswMTbndkggC4Atjv7gfdPQ18Ddgcck3Twt1/Apz9ys/NwH3B+H3AO2ayppng7q3u/nww3kPhh8MS5nnbvaA3mEwGH2eetxvAzJYCbwO+OGz2vG/3KCbc7igFwRLgyLDpo8G8qFjk7q1Q+IEJLAy5nmllZs3ApcDTRKDtwemRrcAJ4BF3j0S7KbwL/aNAfti8KLTbgYfN7DkzuzOYN+F2J6ahwNnKRpine2fnITMrB74FfMjdu81G+qufX9w9B2wwswXA/WZ2ccglTTszuwU44e7PmdmbQi5npl3j7i1mthB4xMz2TObLonREcBRYNmx6KdASUi1haDOzBoBgeCLkeqaFmSUphMBX3f3bwexItB3A3TuBH1G4RjTf230NcKuZHaJwqvfNZvYvzP924+4twfAEcD+FU98TbneUguBZYI2ZrTCzFPAe4Lsh1zSTvgvcEYzfAXwnxFqmhRV+9f8SsNvd/3rYonnddjOrD44EMLMS4EZgD/O83e7+Z+6+1N2bKfx//oG7/xbzvN1mVmZmFWfGgbcAO5hEuyP1ZLGZbaJwTjEO3Ovunwq3oulhZv8KvIlCt7RtwF8C/w58A2gCXgLe5e5nX1Ce08zsWuCnwHZeOWf85xSuE8zbtpvZaylcHIxT+OXuG+7+382slnnc7uGCU0Mfcfdb5nu7zWwlhaMAKJze/3/u/qnJtDtSQSAiIr8sSqeGRERkBAoCEZGIUxCIiEScgkBEJOIUBCIiEacgEBGJOAWBiEjE/X8OqavKWuM6JwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"Get parameters for the model\"\"\"\n",
    "MLP_tx_dim = [input_sizeTx, 256, 256, output_sizeTx]\n",
    "MLP_rx_dim = [input_sizeRx, 128, 128, output_sizeRx]\n",
    "\n",
    "'Calling the model'\n",
    "model = BeamformingModel(MLP_tx_dim, MLP_rx_dim)\n",
    "\n",
    "exp_id = strftime(\"%m-%d_%H_%M_%S\", gmtime())\n",
    "output_dir = f'/Users/seungcheoloh/Desktop/Primary/Research/DNN Applied P_MIMO/Two_Way_Method/trained_TwoWay_model/{exp_id}'\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "print(output_dir)\n",
    "\n",
    "# Setting learning rate and optimizers\n",
    "learning_rate = 0.001\n",
    "optimizer_bf = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "lr_scheduler = optim.lr_scheduler.ExponentialLR(optimizer_bf, gamma=0.9992)\n",
    "\n",
    "# Initializer\n",
    "no_increase = 0 \n",
    "best_loss = float('inf')\n",
    "\n",
    "# Initizalize lists for data visualization\n",
    "training_loss = []\n",
    "test_loss = []\n",
    "epochs = []\n",
    "\n",
    "for epoch in tqdm(range(max_epochs)):\n",
    "    batch_iter = 0\n",
    "    \n",
    "    for epoch_per_batch in range(n_epochs):\n",
    "        model.train()\n",
    "        rnd_indices = torch.randint(num_generated_sample, (batch_size,))\n",
    "        H_p_batch = H_p_training_shaped[rnd_indices]\n",
    "        y_tx_train = y_real_tx_train[rnd_indices]\n",
    "        y_rx_train = y_real_rx_train[rnd_indices]\n",
    "\n",
    "        # Zeros the gradients\n",
    "        optimizer_bf.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        bf = model(H_p_batch, y_tx_train, y_rx_train)\n",
    "        loss = beamforming_loss(bf)\n",
    "        rate_training_loss = -torch.mean(torch.log2(1+SNR*torch.abs(bf)**2))\n",
    "\n",
    "        # Backward propagation\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient Clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Set max_norm to your desired threshold\n",
    "        \n",
    "        # Optimizer\n",
    "        optimizer_bf.step()\n",
    "        lr_scheduler.step()\n",
    "        batch_iter += 1\n",
    "\n",
    "    \"\"\"Evaluating Model\"\"\"\n",
    "    model.eval()\n",
    "    test_bf = model(H_p_testing_batch, y_real_tx_test, y_real_rx_test)\n",
    "    rate_test_loss = -torch.mean(torch.log2(1+SNR*torch.abs(test_bf)**2))\n",
    "\n",
    "    epochs.append(epoch)\n",
    "    test_loss.append(rate_test_loss.detach().numpy())\n",
    "    training_loss.append(rate_training_loss.detach().numpy())\n",
    "    print('epoch', epoch, '  loss_train:%2.5f' % -rate_training_loss, '  loss_test:%2.5f' % -rate_test_loss, '  best_test:%2.5f  ' % -best_loss, 'no_increase:', no_increase, f\"lr: {lr_scheduler.get_lr()}\")\n",
    "    \n",
    "    if rate_test_loss < best_loss:\n",
    "        torch.save(model.state_dict(), os.path.join(output_dir, f\"{epoch}.pth\"))\n",
    "        best_loss = rate_test_loss \n",
    "        no_increase = 0\n",
    "    else: \n",
    "        no_increase = no_increase + 1\n",
    "\n",
    "    if no_increase > 20:\n",
    "        break\n",
    "\n",
    "plt.plot(epochs, training_loss, label='Training Loss')\n",
    "plt.plot(epochs, test_loss, label='Test Loss')\n",
    "plt.savefig(os.path.join(output_dir, f\"training_loss.png\"))\n",
    "plt.savefig(os.path.join(output_dir, f\"test_loss.png\"))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
